# MSRF-NAFNet Configuration
# Optimized for RTX 5090 - Star Removal with Genuine Texture Reconstruction

# Model configuration
model:
  type: msrf_nafnet_s  # Options: msrf_nafnet_s, msrf_nafnet_m, msrf_nafnet_l

# Data configuration
data:
  root_dir: "/workspace"  # Path sul server RunPod
  num_workers: 8  # Increase for faster CPU preprocessing
  patch_size: 512  # Dataset già preparato con tile 512x512
  subset_fraction: 0.3  # Usa solo 30% del dataset per testing veloce

# Training configuration
training:
  # Basic settings
  batch_size: 8  # Ottimizzato per RTX 5090 con gradient checkpointing
  epochs: 500
  
  # Optimization
  use_amp: false  # Disabled - problemi con mixed types
  gradient_accumulation_steps: 2  # Simula batch_size=16
  compile_model: false  # Disabled - torch.compile ha conflitti con AMP
  use_gradient_checkpointing: true  # Riduce VRAM usage drasticamente
  
  # EMA (Exponential Moving Average)
  use_ema: true
  ema_decay: 0.9999
  
  # Intervals
  log_interval: 20  # Log every N steps (ridotto per feedback veloce)
  val_interval: 1  # Validate every N epochs
  save_interval: 5  # Save checkpoint every 5 epochs (ridotto I/O)

# Optimizer configuration
optimizer:
  type: adamw  # Options: adam, adamw
  lr: 0.0002  # Initial learning rate
  beta1: 0.9
  beta2: 0.999
  weight_decay: 0.0001  # L2 regularization

# Learning rate scheduler
scheduler:
  type: cosine_warmup  # Options: cosine, cosine_warmup, step
  min_lr: 0.000001
  warmup_steps: 1000  # Warmup for stable training
  first_cycle_steps: 50000
  cycle_mult: 1.0
  gamma: 0.5

# Loss function weights
loss:
  l1_weight: 1.0  # Pixel-wise L1 loss
  perceptual_weight: 0.5  # VGG perceptual loss (ridotto per velocità)
  texture_weight: 0.3  # Gram matrix texture loss (prevents blob artifacts)
  edge_weight: 0.2  # Edge preservation loss
  frequency_weight: 0.1  # Frequency domain loss

# Output directories
output_dir: "./output"  # All outputs will be saved here
